{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Home work 1</h1> \n",
    "\n",
    "<br>\n",
    "<h2>Classification algorithms comparison</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd \n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('diabetes.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.drop(columns = ['Outcome']))\n",
    "y = np.array(df['Outcome'])\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, inputSize, outputSize):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = (torch.nn.Linear(inputSize, outputSize))\n",
    "    def forward(self, x):\n",
    "        out = torch.sigmoid(self.linear(x))\n",
    "        return out\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "inputDim = x_train.shape[1]\n",
    "outputDim = 2      \n",
    "learningRate = 0.01\n",
    "epochs = 500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(inputDim,outputDim)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(x_train).float()\n",
    "y_train = torch.from_numpy(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   tensor(0.6909, grad_fn=<NllLossBackward>)\n",
      "5000   tensor(0.6100, grad_fn=<NllLossBackward>)\n",
      "10000   tensor(0.6026, grad_fn=<NllLossBackward>)\n",
      "15000   tensor(0.6003, grad_fn=<NllLossBackward>)\n",
      "20000   tensor(0.5991, grad_fn=<NllLossBackward>)\n",
      "25000   tensor(0.5984, grad_fn=<NllLossBackward>)\n",
      "30000   tensor(0.5978, grad_fn=<NllLossBackward>)\n",
      "35000   tensor(0.5974, grad_fn=<NllLossBackward>)\n",
      "40000   tensor(0.5970, grad_fn=<NllLossBackward>)\n",
      "45000   tensor(0.5968, grad_fn=<NllLossBackward>)\n",
      "50000   tensor(0.5965, grad_fn=<NllLossBackward>)\n",
      "55000   tensor(0.5963, grad_fn=<NllLossBackward>)\n",
      "60000   tensor(0.5961, grad_fn=<NllLossBackward>)\n",
      "65000   tensor(0.5959, grad_fn=<NllLossBackward>)\n",
      "70000   tensor(0.5957, grad_fn=<NllLossBackward>)\n",
      "75000   tensor(0.5956, grad_fn=<NllLossBackward>)\n",
      "80000   tensor(0.5955, grad_fn=<NllLossBackward>)\n",
      "85000   tensor(0.5953, grad_fn=<NllLossBackward>)\n",
      "90000   tensor(0.5952, grad_fn=<NllLossBackward>)\n",
      "95000   tensor(0.5951, grad_fn=<NllLossBackward>)\n",
      "100000   tensor(0.5949, grad_fn=<NllLossBackward>)\n",
      "105000   tensor(0.5948, grad_fn=<NllLossBackward>)\n",
      "110000   tensor(0.5947, grad_fn=<NllLossBackward>)\n",
      "115000   tensor(0.5945, grad_fn=<NllLossBackward>)\n",
      "120000   tensor(0.5944, grad_fn=<NllLossBackward>)\n",
      "125000   tensor(0.5943, grad_fn=<NllLossBackward>)\n",
      "130000   tensor(0.5942, grad_fn=<NllLossBackward>)\n",
      "135000   tensor(0.5941, grad_fn=<NllLossBackward>)\n",
      "140000   tensor(0.5940, grad_fn=<NllLossBackward>)\n",
      "145000   tensor(0.5940, grad_fn=<NllLossBackward>)\n",
      "150000   tensor(0.5939, grad_fn=<NllLossBackward>)\n",
      "155000   tensor(0.5938, grad_fn=<NllLossBackward>)\n",
      "160000   tensor(0.5937, grad_fn=<NllLossBackward>)\n",
      "165000   tensor(0.5937, grad_fn=<NllLossBackward>)\n",
      "170000   tensor(0.5936, grad_fn=<NllLossBackward>)\n",
      "175000   tensor(0.5935, grad_fn=<NllLossBackward>)\n",
      "180000   tensor(0.5935, grad_fn=<NllLossBackward>)\n",
      "185000   tensor(0.5934, grad_fn=<NllLossBackward>)\n",
      "190000   tensor(0.5933, grad_fn=<NllLossBackward>)\n",
      "195000   tensor(0.5933, grad_fn=<NllLossBackward>)\n",
      "200000   tensor(0.5932, grad_fn=<NllLossBackward>)\n",
      "205000   tensor(0.5932, grad_fn=<NllLossBackward>)\n",
      "210000   tensor(0.5931, grad_fn=<NllLossBackward>)\n",
      "215000   tensor(0.5931, grad_fn=<NllLossBackward>)\n",
      "220000   tensor(0.5930, grad_fn=<NllLossBackward>)\n",
      "225000   tensor(0.5930, grad_fn=<NllLossBackward>)\n",
      "230000   tensor(0.5929, grad_fn=<NllLossBackward>)\n",
      "235000   tensor(0.5929, grad_fn=<NllLossBackward>)\n",
      "240000   tensor(0.5929, grad_fn=<NllLossBackward>)\n",
      "245000   tensor(0.5928, grad_fn=<NllLossBackward>)\n",
      "250000   tensor(0.5928, grad_fn=<NllLossBackward>)\n",
      "255000   tensor(0.5927, grad_fn=<NllLossBackward>)\n",
      "260000   tensor(0.5927, grad_fn=<NllLossBackward>)\n",
      "265000   tensor(0.5927, grad_fn=<NllLossBackward>)\n",
      "270000   tensor(0.5926, grad_fn=<NllLossBackward>)\n",
      "275000   tensor(0.5926, grad_fn=<NllLossBackward>)\n",
      "280000   tensor(0.5925, grad_fn=<NllLossBackward>)\n",
      "285000   tensor(0.5925, grad_fn=<NllLossBackward>)\n",
      "290000   tensor(0.5925, grad_fn=<NllLossBackward>)\n",
      "295000   tensor(0.5925, grad_fn=<NllLossBackward>)\n",
      "300000   tensor(0.5924, grad_fn=<NllLossBackward>)\n",
      "305000   tensor(0.5924, grad_fn=<NllLossBackward>)\n",
      "310000   tensor(0.5924, grad_fn=<NllLossBackward>)\n",
      "315000   tensor(0.5923, grad_fn=<NllLossBackward>)\n",
      "320000   tensor(0.5923, grad_fn=<NllLossBackward>)\n",
      "325000   tensor(0.5923, grad_fn=<NllLossBackward>)\n",
      "330000   tensor(0.5922, grad_fn=<NllLossBackward>)\n",
      "335000   tensor(0.5922, grad_fn=<NllLossBackward>)\n",
      "340000   tensor(0.5922, grad_fn=<NllLossBackward>)\n",
      "345000   tensor(0.5922, grad_fn=<NllLossBackward>)\n",
      "350000   tensor(0.5921, grad_fn=<NllLossBackward>)\n",
      "355000   tensor(0.5921, grad_fn=<NllLossBackward>)\n",
      "360000   tensor(0.5921, grad_fn=<NllLossBackward>)\n",
      "365000   tensor(0.5921, grad_fn=<NllLossBackward>)\n",
      "370000   tensor(0.5920, grad_fn=<NllLossBackward>)\n",
      "375000   tensor(0.5920, grad_fn=<NllLossBackward>)\n",
      "380000   tensor(0.5920, grad_fn=<NllLossBackward>)\n",
      "385000   tensor(0.5920, grad_fn=<NllLossBackward>)\n",
      "390000   tensor(0.5920, grad_fn=<NllLossBackward>)\n",
      "395000   tensor(0.5919, grad_fn=<NllLossBackward>)\n",
      "400000   tensor(0.5919, grad_fn=<NllLossBackward>)\n",
      "405000   tensor(0.5919, grad_fn=<NllLossBackward>)\n",
      "410000   tensor(0.5919, grad_fn=<NllLossBackward>)\n",
      "415000   tensor(0.5919, grad_fn=<NllLossBackward>)\n",
      "420000   tensor(0.5918, grad_fn=<NllLossBackward>)\n",
      "425000   tensor(0.5918, grad_fn=<NllLossBackward>)\n",
      "430000   tensor(0.5918, grad_fn=<NllLossBackward>)\n",
      "435000   tensor(0.5918, grad_fn=<NllLossBackward>)\n",
      "440000   tensor(0.5918, grad_fn=<NllLossBackward>)\n",
      "445000   tensor(0.5917, grad_fn=<NllLossBackward>)\n",
      "450000   tensor(0.5917, grad_fn=<NllLossBackward>)\n",
      "455000   tensor(0.5917, grad_fn=<NllLossBackward>)\n",
      "460000   tensor(0.5917, grad_fn=<NllLossBackward>)\n",
      "465000   tensor(0.5917, grad_fn=<NllLossBackward>)\n",
      "470000   tensor(0.5917, grad_fn=<NllLossBackward>)\n",
      "475000   tensor(0.5916, grad_fn=<NllLossBackward>)\n",
      "480000   tensor(0.5916, grad_fn=<NllLossBackward>)\n",
      "485000   tensor(0.5916, grad_fn=<NllLossBackward>)\n",
      "490000   tensor(0.5916, grad_fn=<NllLossBackward>)\n",
      "495000   tensor(0.5916, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "Error = []\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(x_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    Error.append(loss)\n",
    "    if (epoch%5000 == 0):\n",
    "        print(epoch, ' ',loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.from_numpy(x_test).float()\n",
    "y_pred = model.forward(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_pred.detach().numpy(),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82       108\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.70       154\n",
      "   macro avg       0.35      0.50      0.41       154\n",
      "weighted avg       0.49      0.70      0.58       154\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YESBOL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\YESBOL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\YESBOL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[108,   0],\n",
       "       [ 46,   0]], dtype=int64)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YESBOL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[86, 22],\n",
       "       [20, 26]], dtype=int64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80       108\n",
      "           1       0.54      0.57      0.55        46\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.68      0.68      0.68       154\n",
      "weighted avg       0.73      0.73      0.73       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Task1</h2>\n",
    "<br>\n",
    "<li> Make a comparison for logistic regression and other 3 different classification/clasterisation algorithms for multiclass classification task and find one with overall accuracy more than 90% You can use all available sources \n",
    "<li> Make a comparative analisys for the observed algorithms and highlight why from your potint of view it shows the best result \n",
    "<li> Use the provided dataset for training and testing \n",
    "<li> Use classification report and confusion matrix for evaluation results \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "выбрал три алгоритма гаусовский НБайес,  Метод опорных векторов, Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC(random_state=17)\n",
    "gnb = GaussianNB()\n",
    "ds = DecisionTreeClassifier(random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подобрать алгоритмам согласно X, y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=17)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(x_train, y_train)\n",
    "gnb.fit(x_train, y_train)\n",
    "ds.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполните классификацию на массиве тестовых векторов X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svc = svc.predict(x_test) \n",
    "y_pred_gnb = gnb.predict(x_test)\n",
    "y_pred_ds = ds.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Support Vector Classifier:\n",
      "[[94 14]\n",
      " [21 25]]\n",
      "XnNaive Bayes:\n",
      "[[83 25]\n",
      " [18 28]]\n",
      "XnDecison Tree:\n",
      "[[79 29]\n",
      " [17 29]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSupport Vector Classifier:\")\n",
    "print(confusion_matrix(y_test, y_pred_svc)) \n",
    "print(\"XnNaive Bayes:\") \n",
    "print(confusion_matrix(y_test, y_pred_gnb))\n",
    "print(\"XnDecison Tree:\") \n",
    "print(confusion_matrix(y_test, y_pred_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       108\n",
      "           1       0.58      0.57      0.57        46\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.70      0.69      0.70       154\n",
      "weighted avg       0.75      0.75      0.75       154\n",
      "\n",
      "\n",
      "Support Vector Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84       108\n",
      "           1       0.64      0.54      0.59        46\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.73      0.71      0.72       154\n",
      "weighted avg       0.76      0.77      0.77       154\n",
      "\n",
      "XnGaussian Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.77      0.79       108\n",
      "           1       0.53      0.61      0.57        46\n",
      "\n",
      "    accuracy                           0.72       154\n",
      "   macro avg       0.68      0.69      0.68       154\n",
      "weighted avg       0.73      0.72      0.73       154\n",
      "\n",
      "XnDecison Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.73      0.77       108\n",
      "           1       0.50      0.63      0.56        46\n",
      "\n",
      "    accuracy                           0.70       154\n",
      "   macro avg       0.66      0.68      0.67       154\n",
      "weighted avg       0.73      0.70      0.71       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSupport Vector Classifier:\")\n",
    "print(classification_report(y_test, y_pred_svc)) \n",
    "print(\"XnGaussian Naive Bayes:\") \n",
    "print(classification_report(y_test, y_pred_gnb))\n",
    "print(\"XnDecison Tree:\") \n",
    "print(classification_report(y_test, y_pred_ds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "результаты получилось алгоритмов ML были схожими с лог рессии DL. Результаты с нейронной сетью тоже не превысили с лог регрессии и МЛ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Task 2 </h2>\n",
    "<br>\n",
    "    <li> adopte logistic regressionfor for multiclassifiction on wine quality dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('winequality-red.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.drop(columns = ['quality']))\n",
    "y = np.array(df['quality'])\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,y,test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver='saga', multi_class='multinomial',max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YESBOL\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, multi_class='multinomial', solver='saga')"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_log = clf.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LogisticRegression:\n",
      "[[  0   0   2   0   0   0]\n",
      " [  0   0   4   8   0   0]\n",
      " [  0   0 104  39   0   0]\n",
      " [  0   0  44  82   0   0]\n",
      " [  0   0   2  32   0   0]\n",
      " [  0   0   0   3   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLogisticRegression:\")\n",
    "print(confusion_matrix(y_test, y_pred_log)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00        12\n",
      "           5       0.67      0.73      0.70       143\n",
      "           6       0.50      0.65      0.57       126\n",
      "           7       0.00      0.00      0.00        34\n",
      "           8       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.58       320\n",
      "   macro avg       0.19      0.23      0.21       320\n",
      "weighted avg       0.49      0.58      0.53       320\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YESBOL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\YESBOL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\YESBOL\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"LogisticRegression:\")\n",
    "print(classification_report(y_test, y_pred_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "этот набор данных немного сложней предыдущей. смотря на результаты . из-за опр параметров снизилось сильно\n",
    "здесь нужно редактировать куалити больше чем аутком в первом случае"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
